{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOeXHuv7OzdpRnINufN8ghT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e9f30bf97694c1490a22f30b033dd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_681317a680f3491da05591649b920527",
              "IPY_MODEL_67eeca48bbc643ee9b433d85b4ebd45e",
              "IPY_MODEL_ab2b6bd5de52492db54f8a659cd5be83"
            ],
            "layout": "IPY_MODEL_66f934928e2e4001ae06e1f502634905"
          }
        },
        "681317a680f3491da05591649b920527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d52f9bb398b4b0e8ce1de798c83b6f4",
            "placeholder": "​",
            "style": "IPY_MODEL_f126cb63537447e68ffa217e903a91e2",
            "value": "README.md: 100%"
          }
        },
        "67eeca48bbc643ee9b433d85b4ebd45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ede71793f284cc3a8c4b661b7e3f16e",
            "max": 10464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_618bdd3b91c14b899f5e902ed8294d65",
            "value": 10464
          }
        },
        "ab2b6bd5de52492db54f8a659cd5be83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3aa7f1f84343ed9cca973dc15aa1e6",
            "placeholder": "​",
            "style": "IPY_MODEL_27b695f184d7457b90caa9724fb6c474",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 996kB/s]"
          }
        },
        "66f934928e2e4001ae06e1f502634905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d52f9bb398b4b0e8ce1de798c83b6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f126cb63537447e68ffa217e903a91e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ede71793f284cc3a8c4b661b7e3f16e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618bdd3b91c14b899f5e902ed8294d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df3aa7f1f84343ed9cca973dc15aa1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b695f184d7457b90caa9724fb6c474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f213201e5a54b6f89a0bb0431956e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0d3dc9436bf4394afc8ddd95e1d8877",
              "IPY_MODEL_03baa6339b684f0b8c267e81a0912533",
              "IPY_MODEL_f2455052a43c4da3917b0f8c36e4170c"
            ],
            "layout": "IPY_MODEL_830c627e7ba54a62adbddf141a5f4bff"
          }
        },
        "a0d3dc9436bf4394afc8ddd95e1d8877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e315acfd7f6c4ad2b16df753cf01251f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f2ddf8c86d14258a9ca11dc75bfad06",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "03baa6339b684f0b8c267e81a0912533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00b4bd6f9024bb0a321c82bd10bee45",
            "max": 732610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92a15b1b32444326b82351e077a6ed0c",
            "value": 732610
          }
        },
        "f2455052a43c4da3917b0f8c36e4170c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3871ab2c624248a997d592c0a01fa053",
            "placeholder": "​",
            "style": "IPY_MODEL_0016211e04264500bdc7f8dc1b1c112c",
            "value": " 733k/733k [00:00&lt;00:00, 44.6MB/s]"
          }
        },
        "830c627e7ba54a62adbddf141a5f4bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e315acfd7f6c4ad2b16df753cf01251f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f2ddf8c86d14258a9ca11dc75bfad06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b00b4bd6f9024bb0a321c82bd10bee45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a15b1b32444326b82351e077a6ed0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3871ab2c624248a997d592c0a01fa053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0016211e04264500bdc7f8dc1b1c112c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84154289f5e14a998c0650759d1f65e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aa6c48db92f4a3098094159791a6237",
              "IPY_MODEL_9a433eae7830416db7a4429192dcd09c",
              "IPY_MODEL_a6f63f9a52404b0eb4eda168b8256df4"
            ],
            "layout": "IPY_MODEL_91c086ad9e8b4755b073e59ac3a21b36"
          }
        },
        "2aa6c48db92f4a3098094159791a6237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb1fd81120be4667a12ad7da9f2632a3",
            "placeholder": "​",
            "style": "IPY_MODEL_233f8cecd721468091b9e48d45228a3b",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "9a433eae7830416db7a4429192dcd09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1787e67aad44498b248e4b94a622ea7",
            "max": 6357543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bceebeaed89a47e1923bffd69f824d2f",
            "value": 6357543
          }
        },
        "a6f63f9a52404b0eb4eda168b8256df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b791f660d5664fdcb42f645a987172d0",
            "placeholder": "​",
            "style": "IPY_MODEL_0fd7d3a8724446d79714a0c42089d133",
            "value": " 6.36M/6.36M [00:00&lt;00:00, 252MB/s]"
          }
        },
        "91c086ad9e8b4755b073e59ac3a21b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb1fd81120be4667a12ad7da9f2632a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233f8cecd721468091b9e48d45228a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1787e67aad44498b248e4b94a622ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bceebeaed89a47e1923bffd69f824d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b791f660d5664fdcb42f645a987172d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd7d3a8724446d79714a0c42089d133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01109a63f76342e88ae239d69569ce31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e31cf69f8d6f4a9e97f8be27bef086bd",
              "IPY_MODEL_60f08449fe054d89895a54e718cb1c7c",
              "IPY_MODEL_50441ca6db42433e98b16fa37bdafbc6"
            ],
            "layout": "IPY_MODEL_4a35445f62ba42b1a1c497b41a3c8384"
          }
        },
        "e31cf69f8d6f4a9e97f8be27bef086bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee43bf599764477c981fd7b039449e4a",
            "placeholder": "​",
            "style": "IPY_MODEL_76f92cc800df49039bc9bd7fe0486c49",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "60f08449fe054d89895a54e718cb1c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d33911663234db197f701549e7ee0c0",
            "max": 657209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d4ff4338727466e8da8bc2f20d84f69",
            "value": 657209
          }
        },
        "50441ca6db42433e98b16fa37bdafbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7505ad2d1d774885a7d68942bae64a64",
            "placeholder": "​",
            "style": "IPY_MODEL_63626abb255b427f9f437a35aef7df71",
            "value": " 657k/657k [00:00&lt;00:00, 69.9MB/s]"
          }
        },
        "4a35445f62ba42b1a1c497b41a3c8384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee43bf599764477c981fd7b039449e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f92cc800df49039bc9bd7fe0486c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d33911663234db197f701549e7ee0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4ff4338727466e8da8bc2f20d84f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7505ad2d1d774885a7d68942bae64a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63626abb255b427f9f437a35aef7df71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "853340ecb8c040cbad0a58a87ab68693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2803d1a161ba4c0daf812f0bd6f066ef",
              "IPY_MODEL_cd124d34edc44fa0842fc4f02cf58ea0",
              "IPY_MODEL_07356f3ee74b4164b0cb7df6490376a5"
            ],
            "layout": "IPY_MODEL_fe2c51ebac7b44b88748abc92cd648ef"
          }
        },
        "2803d1a161ba4c0daf812f0bd6f066ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a38a24bb15b4f04ae82ba09e7be89c8",
            "placeholder": "​",
            "style": "IPY_MODEL_c98e65a33bd4439e877736bdb2620dcf",
            "value": "Generating test split: 100%"
          }
        },
        "cd124d34edc44fa0842fc4f02cf58ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa92a03bf0941ea9b43c594a2d5457a",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66f034c0447b4b46942dfede3d8cd00f",
            "value": 4358
          }
        },
        "07356f3ee74b4164b0cb7df6490376a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a41f0b13a8b4572807e815b5bd347f4",
            "placeholder": "​",
            "style": "IPY_MODEL_bd4879f4304b47178524cdb70630938b",
            "value": " 4358/4358 [00:00&lt;00:00, 85923.16 examples/s]"
          }
        },
        "fe2c51ebac7b44b88748abc92cd648ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a38a24bb15b4f04ae82ba09e7be89c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98e65a33bd4439e877736bdb2620dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfa92a03bf0941ea9b43c594a2d5457a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f034c0447b4b46942dfede3d8cd00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a41f0b13a8b4572807e815b5bd347f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd4879f4304b47178524cdb70630938b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a14bba919c84ab0991d72ed8fe6e68b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_903f57706810481b9edeb668464f60e6",
              "IPY_MODEL_03a9dff5ac4843568c5028c1fddaaf75",
              "IPY_MODEL_f4bf746a17174952bdc5c02d03dfa2d3"
            ],
            "layout": "IPY_MODEL_dc575de832404ff39afe2d16d346e88f"
          }
        },
        "903f57706810481b9edeb668464f60e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe1609f0d923439d81fd1b85680cc999",
            "placeholder": "​",
            "style": "IPY_MODEL_78d92c9a1f47412a97565149a29d0846",
            "value": "Generating train split: 100%"
          }
        },
        "03a9dff5ac4843568c5028c1fddaaf75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d454361734149d7879cbfeac220721c",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3c30cf8cd874bdebcb2a8a02dfcc42d",
            "value": 36718
          }
        },
        "f4bf746a17174952bdc5c02d03dfa2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d8c5c0c6e644349d5f5ed6f925a2a9",
            "placeholder": "​",
            "style": "IPY_MODEL_33e75c4c07af4735b3be52126cf7ff6c",
            "value": " 36718/36718 [00:00&lt;00:00, 665088.03 examples/s]"
          }
        },
        "dc575de832404ff39afe2d16d346e88f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1609f0d923439d81fd1b85680cc999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78d92c9a1f47412a97565149a29d0846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d454361734149d7879cbfeac220721c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3c30cf8cd874bdebcb2a8a02dfcc42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d8c5c0c6e644349d5f5ed6f925a2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33e75c4c07af4735b3be52126cf7ff6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a4c6d407c5a44dbaa0b7d4b35dcb346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25b58e28896a42028152c9926b7d34e5",
              "IPY_MODEL_5214b26364154e88a56ac01d9933ed63",
              "IPY_MODEL_72672d9857574cf8b89b12bd5108bec6"
            ],
            "layout": "IPY_MODEL_461dfe2a0588429dac470ed6222c494c"
          }
        },
        "25b58e28896a42028152c9926b7d34e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b419d53536d4d8ebebe57354b1eabac",
            "placeholder": "​",
            "style": "IPY_MODEL_063a9a89c2fb41b2af476a97d43e2c47",
            "value": "Generating validation split: 100%"
          }
        },
        "5214b26364154e88a56ac01d9933ed63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd6ee564784473bb9cf2ab181f5abf8",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5183da6da5c478bb5a8c9e6ca83de07",
            "value": 3760
          }
        },
        "72672d9857574cf8b89b12bd5108bec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b78ce02eaaf340dbb81596b8e9122dec",
            "placeholder": "​",
            "style": "IPY_MODEL_00bfea46f7a54b97b607c6717468ef5d",
            "value": " 3760/3760 [00:00&lt;00:00, 216281.29 examples/s]"
          }
        },
        "461dfe2a0588429dac470ed6222c494c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b419d53536d4d8ebebe57354b1eabac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063a9a89c2fb41b2af476a97d43e2c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccd6ee564784473bb9cf2ab181f5abf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5183da6da5c478bb5a8c9e6ca83de07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b78ce02eaaf340dbb81596b8e9122dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00bfea46f7a54b97b607c6717468ef5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agatsyadav2003/quantized-llm-mobile/blob/main/Perplexity_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko2YX7aNmWry",
        "outputId": "c1076808-ff84-4d08-9aaa-9dfad22db7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 49519, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 49519 (delta 123), reused 72 (delta 70), pack-reused 49354 (from 3)\u001b[K\n",
            "Receiving objects: 100% (49519/49519), 103.31 MiB | 16.19 MiB/s, done.\n",
            "Resolving deltas: 100% (35696/35696), done.\n",
            "/content/llama.cpp\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.5.82\")\n",
            "-- CUDA Toolkit found\n",
            "-- Using CUDA architectures: native\n",
            "-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler GNU 11.4.0\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "\u001b[0m-- CUDA host compiler is GNU 11.4.0\n",
            "\u001b[0m\n",
            "-- Including CUDA backend\n",
            "-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")\n",
            "-- Configuring done (9.8s)\n",
            "-- Generating done (0.3s)\n",
            "-- Build files have been written to: /content/llama.cpp/build\n",
            "[  0%] \u001b[34m\u001b[1mGenerating build details from Git\u001b[0m\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "[  6%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n",
            "[  6%] Built target build_info\n",
            "[  6%] Built target sha1\n",
            "[  7%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-minicpmv-cli\u001b[0m\n",
            "[  7%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-llava-cli\u001b[0m\n",
            "[  7%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gemma3-cli\u001b[0m\n",
            "[  7%] Built target sha256\n",
            "[  7%] Built target llama-minicpmv-cli\n",
            "[  7%] Built target llama-gemma3-cli\n",
            "[  7%] Built target llama-llava-cli\n",
            "[  7%] Built target xxhash\n",
            "[  7%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n",
            "[  7%] Built target ggml-base\n",
            "[  7%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmv.cu.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o\u001b[0m\n",
            "[ 39%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n",
            "[ 39%] Built target ggml-cpu\n",
            "[ 39%] \u001b[32m\u001b[1mLinking CUDA shared library ../../../bin/libggml-cuda.so\u001b[0m\n",
            "[ 39%] Built target ggml-cuda\n",
            "[ 39%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n",
            "[ 39%] Built target ggml\n",
            "[ 40%] \u001b[32mBuilding CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf\u001b[0m\n",
            "[ 47%] Built target llama-gguf\n",
            "[ 47%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-hash\u001b[0m\n",
            "[ 47%] Built target llama-gguf-hash\n",
            "[ 48%] \u001b[32m\u001b[1mLinking CXX shared library ../bin/libllama.so\u001b[0m\n",
            "[ 48%] Built target llama\n",
            "[ 48%] \u001b[32mBuilding C object tests/CMakeFiles/test-c.dir/test-c.c.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/mtmd.dir/mtmd.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/mtmd.dir/clip.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llava.dir/llava.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llava.dir/clip.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32m\u001b[1mLinking C executable ../bin/test-c\u001b[0m\n",
            "[ 52%] Built target test-c\n",
            "[ 53%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple\u001b[0m\n",
            "[ 53%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple-chat\u001b[0m\n",
            "[ 53%] Built target llama-simple\n",
            "[ 53%] Built target llama-simple-chat\n",
            "[ 53%] Built target mtmd\n",
            "[ 53%] \u001b[32m\u001b[1mLinking CXX static library libmtmd_static.a\u001b[0m\n",
            "[ 54%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libmtmd_shared.so\u001b[0m\n",
            "[ 54%] Built target mtmd_shared\n",
            "[ 54%] Built target llava\n",
            "[ 55%] \u001b[32m\u001b[1mLinking CXX static library libllava_static.a\u001b[0m\n",
            "[ 55%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libllava_shared.so\u001b[0m\n",
            "[ 55%] Built target llava_shared\n",
            "[ 55%] Built target llava_static\n",
            "[ 55%] Built target mtmd_static\n",
            "[ 56%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 56%] Built target common\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object examples/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object examples/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object examples/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object examples/infill/CMakeFiles/llama-infill.dir/infill.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-model-load-cancel\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object examples/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object examples/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object examples/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object examples/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[34m\u001b[1mGenerating loading.html.hpp\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[34m\u001b[1mGenerating index.html.gz.hpp\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object examples/run/CMakeFiles/llama-run.dir/run.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object examples/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\u001b[0m\n",
            "[ 72%] Built target test-model-load-cancel\n",
            "[ 72%] \u001b[32mBuilding CXX object examples/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/qwen2vl-cli.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object examples/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/clip-quantize-cli.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object examples/llava/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-log\u001b[0m\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-autorelease\u001b[0m\n",
            "[ 78%] Built target test-log\n",
            "[ 78%] Built target test-autorelease\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-rope\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-barrier\u001b[0m\n",
            "[ 79%] Built target test-barrier\n",
            "[ 79%] Built target test-rope\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-fns\u001b[0m\n",
            "[ 80%] Built target test-quantize-fns\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-merge\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gritlm\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-llava-clip-quantize-cli\u001b[0m\n",
            "[ 81%] Built target llama-lookup-merge\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-spm\u001b[0m\n",
            "[ 81%] Built target test-tokenizer-1-spm\n",
            "[ 81%] Built target llama-llava-clip-quantize-cli\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched-bench\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-vdot\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tokenize\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-bpe\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-q8dot\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n",
            "[ 83%] Built target llama-tokenize\n",
            "[ 83%] Built target test-tokenizer-1-bpe\n",
            "[ 83%] Built target llama-gritlm\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-0\u001b[0m\n",
            "[ 83%] Built target llama-vdot\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-parser\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-sampling\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gbnf-validator\u001b[0m\n",
            "[ 84%] Built target llama-batched\n",
            "[ 84%] Built target llama-gguf-split\n",
            "[ 84%] Built target llama-q8dot\n",
            "[ 84%] Built target test-tokenizer-0\n",
            "[ 84%] Built target test-sampling\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-create\u001b[0m\n",
            "[ 84%] Built target test-gbnf-validator\n",
            "[ 84%] Built target test-grammar-parser\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-convert-llama2c-to-ggml\u001b[0m\n",
            "[ 84%] Built target llama-batched-bench\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-llama-grammar\u001b[0m\n",
            "[ 85%] Built target llama-lookup-create\n",
            "[ 85%] Built target llama-convert-llama2c-to-ggml\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gen-docs\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-perf\u001b[0m\n",
            "[ 87%] Built target test-llama-grammar\n",
            "[ 87%] Built target test-quantize-perf\n",
            "[ 87%] Built target llama-lookup\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-embedding\u001b[0m\n",
            "[ 88%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-save-load-state\u001b[0m\n",
            "[ 88%] Built target llama-gen-docs\n",
            "[ 89%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-eval-callback\u001b[0m\n",
            "[ 89%] Built target llama-embedding\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative-simple\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-passkey\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookahead\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-parallel\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-arg-parser\u001b[0m\n",
            "[ 93%] Built target llama-eval-callback\n",
            "[ 93%] Built target llama-speculative-simple\n",
            "[ 93%] Built target llama-passkey\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-stats\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-qwen2vl-cli\u001b[0m\n",
            "[ 93%] Built target llama-save-load-state\n",
            "[ 93%] Built target test-arg-parser\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-retrieval\u001b[0m\n",
            "[ 93%] Built target llama-lookup-stats\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gguf\u001b[0m\n",
            "[ 93%] Built target llama-qwen2vl-cli\n",
            "[ 93%] Built target test-gguf\n",
            "[ 93%] Built target llama-lookahead\n",
            "[ 93%] Built target llama-parallel\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-export-lora\u001b[0m\n",
            "[ 93%] Built target llama-retrieval\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-infill\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat-template\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-mtmd-cli\u001b[0m\n",
            "[ 94%] Built target llama-export-lora\n",
            "[ 94%] Built target test-chat-template\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object examples/server/CMakeFiles/llama-server.dir/server.cpp.o\u001b[0m\n",
            "[ 96%] Built target llama-infill\n",
            "[ 96%] Built target llama-mtmd-cli\n",
            "[ 96%] Built target llama-quantize\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative\u001b[0m\n",
            "[ 96%] Built target llama-speculative\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cvector-generator\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-imatrix\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cli\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-perplexity\u001b[0m\n",
            "[ 96%] Built target llama-cvector-generator\n",
            "[ 96%] Built target llama-cli\n",
            "[ 96%] Built target llama-imatrix\n",
            "[ 96%] Built target llama-perplexity\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-stats\u001b[0m\n",
            "[ 96%] Built target test-quantize-stats\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-run\u001b[0m\n",
            "[ 96%] Built target llama-run\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-integration\u001b[0m\n",
            "[ 97%] Built target test-grammar-integration\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-json-schema-to-grammar\u001b[0m\n",
            "[ 98%] Built target test-json-schema-to-grammar\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-bench\u001b[0m\n",
            "[ 99%] Built target llama-bench\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tts\u001b[0m\n",
            "[ 99%] Built target llama-tts\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat\u001b[0m\n",
            "[ 99%] Built target test-chat\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-backend-ops\u001b[0m\n",
            "[100%] Built target test-backend-ops\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-server\u001b[0m\n",
            "[100%] Built target llama-server\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Install necessary dependencies\n",
        "!pip install -q sentencepiece cmake\n",
        "\n",
        "# Clone the llama.cpp repository\n",
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "%cd llama.cpp\n",
        "!mkdir build && cd build && cmake -DGGML_CUDA=on .. && make -j\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/llama.cpp/build/bin/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADRLkwmKm8kg",
        "outputId": "cdc2c5f6-5067-4d7b-f4bb-5a2d2d6cc253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "libggml-base.so\t\t       llama-quantize\n",
            "libggml-cpu.so\t\t       llama-qwen2vl-cli\n",
            "libggml-cuda.so\t\t       llama-retrieval\n",
            "libggml.so\t\t       llama-run\n",
            "libllama.so\t\t       llama-save-load-state\n",
            "libllava_shared.so\t       llama-server\n",
            "libmtmd_shared.so\t       llama-simple\n",
            "llama-batched\t\t       llama-simple-chat\n",
            "llama-batched-bench\t       llama-speculative\n",
            "llama-bench\t\t       llama-speculative-simple\n",
            "llama-cli\t\t       llama-tokenize\n",
            "llama-convert-llama2c-to-ggml  llama-tts\n",
            "llama-cvector-generator        llama-vdot\n",
            "llama-embedding\t\t       test-arg-parser\n",
            "llama-eval-callback\t       test-autorelease\n",
            "llama-export-lora\t       test-backend-ops\n",
            "llama-gemma3-cli\t       test-barrier\n",
            "llama-gen-docs\t\t       test-c\n",
            "llama-gguf\t\t       test-chat\n",
            "llama-gguf-hash\t\t       test-chat-template\n",
            "llama-gguf-split\t       test-gbnf-validator\n",
            "llama-gritlm\t\t       test-gguf\n",
            "llama-imatrix\t\t       test-grammar-integration\n",
            "llama-infill\t\t       test-grammar-parser\n",
            "llama-llava-cli\t\t       test-json-schema-to-grammar\n",
            "llama-llava-clip-quantize-cli  test-llama-grammar\n",
            "llama-lookahead\t\t       test-log\n",
            "llama-lookup\t\t       test-model-load-cancel\n",
            "llama-lookup-create\t       test-quantize-fns\n",
            "llama-lookup-merge\t       test-quantize-perf\n",
            "llama-lookup-stats\t       test-quantize-stats\n",
            "llama-minicpmv-cli\t       test-rope\n",
            "llama-mtmd-cli\t\t       test-sampling\n",
            "llama-parallel\t\t       test-tokenizer-0\n",
            "llama-passkey\t\t       test-tokenizer-1-bpe\n",
            "llama-perplexity\t       test-tokenizer-1-spm\n",
            "llama-q8dot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the uploaded file into your llama.cpp folder\n",
        "!mv /content/llama_3.2_3b_q4_k_m.gguf /content/llama.cpp/"
      ],
      "metadata": {
        "id": "SlXGLXOqo9LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create examples directory in the correct location and download the dataset\n",
        "!mkdir -p /content/llama.cpp/examples\n",
        "!pip install -q datasets\n",
        "\n",
        "# Use Python to fetch & write out the raw test set\n",
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
        "\n",
        "with open(\"/content/llama.cpp/examples/wikitext-2-raw.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in ds[\"text\"]:\n",
        "        f.write(line.rstrip() + \"\\n\")\n"
      ],
      "metadata": {
        "id": "luvibx7MpJtS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "8e9f30bf97694c1490a22f30b033dd34",
            "681317a680f3491da05591649b920527",
            "67eeca48bbc643ee9b433d85b4ebd45e",
            "ab2b6bd5de52492db54f8a659cd5be83",
            "66f934928e2e4001ae06e1f502634905",
            "7d52f9bb398b4b0e8ce1de798c83b6f4",
            "f126cb63537447e68ffa217e903a91e2",
            "2ede71793f284cc3a8c4b661b7e3f16e",
            "618bdd3b91c14b899f5e902ed8294d65",
            "df3aa7f1f84343ed9cca973dc15aa1e6",
            "27b695f184d7457b90caa9724fb6c474",
            "1f213201e5a54b6f89a0bb0431956e8c",
            "a0d3dc9436bf4394afc8ddd95e1d8877",
            "03baa6339b684f0b8c267e81a0912533",
            "f2455052a43c4da3917b0f8c36e4170c",
            "830c627e7ba54a62adbddf141a5f4bff",
            "e315acfd7f6c4ad2b16df753cf01251f",
            "1f2ddf8c86d14258a9ca11dc75bfad06",
            "b00b4bd6f9024bb0a321c82bd10bee45",
            "92a15b1b32444326b82351e077a6ed0c",
            "3871ab2c624248a997d592c0a01fa053",
            "0016211e04264500bdc7f8dc1b1c112c",
            "84154289f5e14a998c0650759d1f65e1",
            "2aa6c48db92f4a3098094159791a6237",
            "9a433eae7830416db7a4429192dcd09c",
            "a6f63f9a52404b0eb4eda168b8256df4",
            "91c086ad9e8b4755b073e59ac3a21b36",
            "bb1fd81120be4667a12ad7da9f2632a3",
            "233f8cecd721468091b9e48d45228a3b",
            "a1787e67aad44498b248e4b94a622ea7",
            "bceebeaed89a47e1923bffd69f824d2f",
            "b791f660d5664fdcb42f645a987172d0",
            "0fd7d3a8724446d79714a0c42089d133",
            "01109a63f76342e88ae239d69569ce31",
            "e31cf69f8d6f4a9e97f8be27bef086bd",
            "60f08449fe054d89895a54e718cb1c7c",
            "50441ca6db42433e98b16fa37bdafbc6",
            "4a35445f62ba42b1a1c497b41a3c8384",
            "ee43bf599764477c981fd7b039449e4a",
            "76f92cc800df49039bc9bd7fe0486c49",
            "3d33911663234db197f701549e7ee0c0",
            "6d4ff4338727466e8da8bc2f20d84f69",
            "7505ad2d1d774885a7d68942bae64a64",
            "63626abb255b427f9f437a35aef7df71",
            "853340ecb8c040cbad0a58a87ab68693",
            "2803d1a161ba4c0daf812f0bd6f066ef",
            "cd124d34edc44fa0842fc4f02cf58ea0",
            "07356f3ee74b4164b0cb7df6490376a5",
            "fe2c51ebac7b44b88748abc92cd648ef",
            "9a38a24bb15b4f04ae82ba09e7be89c8",
            "c98e65a33bd4439e877736bdb2620dcf",
            "dfa92a03bf0941ea9b43c594a2d5457a",
            "66f034c0447b4b46942dfede3d8cd00f",
            "3a41f0b13a8b4572807e815b5bd347f4",
            "bd4879f4304b47178524cdb70630938b",
            "3a14bba919c84ab0991d72ed8fe6e68b",
            "903f57706810481b9edeb668464f60e6",
            "03a9dff5ac4843568c5028c1fddaaf75",
            "f4bf746a17174952bdc5c02d03dfa2d3",
            "dc575de832404ff39afe2d16d346e88f",
            "fe1609f0d923439d81fd1b85680cc999",
            "78d92c9a1f47412a97565149a29d0846",
            "0d454361734149d7879cbfeac220721c",
            "a3c30cf8cd874bdebcb2a8a02dfcc42d",
            "09d8c5c0c6e644349d5f5ed6f925a2a9",
            "33e75c4c07af4735b3be52126cf7ff6c",
            "2a4c6d407c5a44dbaa0b7d4b35dcb346",
            "25b58e28896a42028152c9926b7d34e5",
            "5214b26364154e88a56ac01d9933ed63",
            "72672d9857574cf8b89b12bd5108bec6",
            "461dfe2a0588429dac470ed6222c494c",
            "4b419d53536d4d8ebebe57354b1eabac",
            "063a9a89c2fb41b2af476a97d43e2c47",
            "ccd6ee564784473bb9cf2ab181f5abf8",
            "b5183da6da5c478bb5a8c9e6ca83de07",
            "b78ce02eaaf340dbb81596b8e9122dec",
            "00bfea46f7a54b97b607c6717468ef5d"
          ]
        },
        "outputId": "c29d696f-5862-44e6-92f4-1df333a43f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e9f30bf97694c1490a22f30b033dd34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f213201e5a54b6f89a0bb0431956e8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84154289f5e14a998c0650759d1f65e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01109a63f76342e88ae239d69569ce31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "853340ecb8c040cbad0a58a87ab68693"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a14bba919c84ab0991d72ed8fe6e68b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a4c6d407c5a44dbaa0b7d4b35dcb346"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/llama.cpp/build/bin && \\\n",
        "  ./llama-perplexity \\\n",
        "    -m ../../llama_3.2_3b_q4_k_m.gguf \\\n",
        "    -f ../../examples/wikitext-2-raw.txt \\\n",
        "    -ngl 33 \\\n",
        "    -t 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtIN6vLZpkaJ",
        "outputId": "270b60af-b88d-40b5-9420-50c527493723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: NVIDIA L4, compute capability 8.9, VMM: yes\n",
            "build: 5215 (5f5e39e1) with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA L4) - 22503 MiB free\n",
            "llama_model_loader: loaded meta data with 27 key-value pairs and 255 tensors from ../../llama_3.2_3b_q4_k_m.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3B\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Meta Llama\n",
            "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 3B\n",
            "llama_model_loader: - kv   6:                          llama.block_count u32              = 28\n",
            "llama_model_loader: - kv   7:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   8:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   9:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv  10:                 llama.attention.head_count u32              = 24\n",
            "llama_model_loader: - kv  11:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  13:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  14:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  15:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  26:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:   58 tensors\n",
            "llama_model_loader: - type q4_K:  168 tensors\n",
            "llama_model_loader: - type q6_K:   29 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 1.87 GiB (5.01 BPW) \n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.7999 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 3072\n",
            "print_info: n_layer          = 28\n",
            "print_info: n_head           = 24\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_swa_pattern    = 1\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 3\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 8192\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 131072\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 3B\n",
            "print_info: model params     = 3.21 B\n",
            "print_info: general.name     = Llama 3.2 3B\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: EOM token        = 128008 '<|eom_id|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
            "print_info: EOG token        = 128008 '<|eom_id|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: offloading 28 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 29/29 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size =  1918.35 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   308.23 MiB\n",
            "...........................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 4\n",
            "llama_context: n_ctx         = 2048\n",
            "llama_context: n_ctx_per_seq = 512\n",
            "llama_context: n_batch       = 2048\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: freq_base     = 500000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "llama_context:  CUDA_Host  output buffer size =     1.96 MiB\n",
            "init: kv_size = 2048, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
            "init:      CUDA0 KV buffer size =   224.00 MiB\n",
            "llama_context: KV self size  =  224.00 MiB, K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
            "llama_context:      CUDA0 compute buffer size =   256.50 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    10.01 MiB\n",
            "llama_context: graph nodes  = 958\n",
            "llama_context: graph splits = 2\n",
            "common_init_from_params: setting dry_penalty_last_n to ctx_size = 2048\n",
            "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
            "\n",
            "system_info: n_threads = 4 (n_threads_batch = 4) / 12 | CUDA : ARCHS = 890 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "perplexity: tokenizing the input ..\n",
            "perplexity: tokenization took 287.81 ms\n",
            "perplexity: calculating perplexity over 559 chunks, n_ctx=512, batch_size=2048, n_seq=4\n",
            "perplexity: 0.74 seconds per pass - ETA 1.72 minutes\n",
            "[1]4.7480,[2]6.0505,[3]7.0780,[4]7.7001,[5]7.9921,[6]8.3622,[7]8.7001,[8]9.3928,[9]10.0395,[10]10.1441,[11]10.3752,[12]10.5202,[13]10.8687,[14]10.3130,[15]10.3425,[16]9.6959,[17]9.6891,[18]9.6138,[19]9.4837,[20]9.2860,[21]9.3081,[22]8.9394,[23]8.6176,[24]8.5193,[25]8.2604,[26]8.1461,[27]8.1801,[28]8.1142,[29]8.1578,[30]8.0585,[31]8.0050,[32]8.0071,[33]8.0438,[34]8.1832,[35]8.2792,[36]8.2505,[37]8.2390,[38]8.2420,[39]8.1975,[40]8.2587,[41]8.2780,[42]8.1893,[43]8.1820,[44]8.2324,[45]8.2985,[46]8.3355,[47]8.3620,[48]8.4476,[49]8.4676,[50]8.5036,[51]8.5658,[52]8.5662,[53]8.6235,[54]8.6134,[55]8.6011,[56]8.5990,[57]8.6216,[58]8.6322,[59]8.6932,[60]8.7366,[61]8.8016,[62]8.8446,[63]8.8688,[64]8.8966,[65]8.9149,[66]8.9292,[67]8.9193,[68]8.9724,[69]8.9563,[70]8.9796,[71]8.9545,[72]8.9674,[73]8.9874,[74]8.9670,[75]8.9391,[76]8.9098,[77]8.8943,[78]8.9054,[79]8.9322,[80]8.9222,[81]8.9366,[82]8.9395,[83]8.9560,[84]8.9481,[85]8.9263,[86]8.9675,[87]8.9680,[88]8.9566,[89]8.9763,[90]8.9777,[91]8.9901,[92]8.9929,[93]9.0336,[94]9.0178,[95]9.0840,[96]9.1138,[97]9.1048,[98]9.1096,[99]9.0800,[100]9.0664,[101]9.0784,[102]9.1224,[103]9.1765,[104]9.1721,[105]9.2405,[106]9.2707,[107]9.2836,[108]9.3240,[109]9.3678,[110]9.3760,[111]9.3338,[112]9.3188,[113]9.3098,[114]9.2800,[115]9.2747,[116]9.2703,[117]9.2358,[118]9.2018,[119]9.1732,[120]9.1521,[121]9.1253,[122]9.1074,[123]9.0502,[124]8.9997,[125]8.9510,[126]8.9158,[127]8.9103,[128]8.9097,[129]8.9037,[130]8.9115,[131]8.8837,[132]8.8456,[133]8.8546,[134]8.8484,[135]8.8567,[136]8.8475,[137]8.8495,[138]8.8942,[139]8.8396,[140]8.8005,[141]8.7686,[142]8.7125,[143]8.6477,[144]8.6132,[145]8.5936,[146]8.5583,[147]8.5155,[148]8.5059,[149]8.4656,[150]8.4382,[151]8.3985,[152]8.3510,[153]8.3162,[154]8.2957,[155]8.2601,[156]8.2225,[157]8.2086,[158]8.2220,[159]8.2180,[160]8.2292,[161]8.2226,[162]8.2590,[163]8.2831,[164]8.3252,[165]8.3679,[166]8.3893,[167]8.4463,[168]8.4765,[169]8.5199,[170]8.5677,[171]8.5757,[172]8.5680,[173]8.6064,[174]8.6321,[175]8.6359,[176]8.6342,[177]8.6324,[178]8.6487,[179]8.6565,[180]8.6606,[181]8.6846,[182]8.7131,[183]8.7195,[184]8.7145,[185]8.7473,[186]8.7689,[187]8.7877,[188]8.7918,[189]8.7739,[190]8.7609,[191]8.7396,[192]8.7413,[193]8.7668,[194]8.7856,[195]8.7985,[196]8.8066,[197]8.7941,[198]8.7839,[199]8.7467,[200]8.7559,[201]8.7305,[202]8.7201,[203]8.7009,[204]8.6968,[205]8.6842,[206]8.6899,[207]8.6842,[208]8.6755,[209]8.6600,[210]8.6289,[211]8.6186,[212]8.6021,[213]8.5990,[214]8.6012,[215]8.5766,[216]8.5537,[217]8.5432,[218]8.5383,[219]8.5181,[220]8.5010,[221]8.4911,[222]8.4827,[223]8.4825,[224]8.4724,[225]8.4452,[226]8.4382,[227]8.4221,[228]8.4093,[229]8.4107,[230]8.4092,[231]8.4151,[232]8.4135,[233]8.4311,[234]8.4324,[235]8.4496,[236]8.4608,[237]8.4744,[238]8.4867,[239]8.4944,[240]8.5097,[241]8.5117,[242]8.5305,[243]8.5566,[244]8.5679,[245]8.5692,[246]8.5763,[247]8.5656,[248]8.5357,[249]8.5222,[250]8.4986,[251]8.4902,[252]8.4864,[253]8.4932,[254]8.4899,[255]8.4816,[256]8.4709,[257]8.4704,[258]8.4562,[259]8.4417,[260]8.4307,[261]8.4189,[262]8.4112,[263]8.4145,[264]8.3933,[265]8.3868,[266]8.3786,[267]8.3763,[268]8.3751,[269]8.3506,[270]8.3520,[271]8.3186,[272]8.3441,[273]8.3435,[274]8.3353,[275]8.3450,[276]8.3419,[277]8.3612,[278]8.3637,[279]8.3644,[280]8.3660,[281]8.3730,[282]8.3869,[283]8.3935,[284]8.4020,[285]8.3926,[286]8.3816,[287]8.3770,[288]8.3724,[289]8.3656,[290]8.3569,[291]8.3636,[292]8.3651,[293]8.3669,[294]8.3613,[295]8.3581,[296]8.3537,[297]8.3553,[298]8.3559,[299]8.3522,[300]8.3533,[301]8.3473,[302]8.3462,[303]8.3565,[304]8.3617,[305]8.3526,[306]8.3599,[307]8.3432,[308]8.3577,[309]8.3701,[310]8.3886,[311]8.4115,[312]8.4150,[313]8.4073,[314]8.4056,[315]8.3993,[316]8.3953,[317]8.3791,[318]8.3753,[319]8.3718,[320]8.3714,[321]8.3573,[322]8.3458,[323]8.3418,[324]8.3469,[325]8.3308,[326]8.3279,[327]8.3100,[328]8.3163,[329]8.3078,[330]8.3032,[331]8.3016,[332]8.2850,[333]8.2825,[334]8.2711,[335]8.2659,[336]8.2603,[337]8.2631,[338]8.2630,[339]8.2661,[340]8.2749,[341]8.2923,[342]8.2929,[343]8.2929,[344]8.2942,[345]8.2989,[346]8.2974,[347]8.2988,[348]8.3021,[349]8.3101,[350]8.3334,[351]8.3511,[352]8.3708,[353]8.3900,[354]8.4057,[355]8.4262,[356]8.4464,[357]8.4530,[358]8.4606,[359]8.4791,[360]8.4881,[361]8.4947,[362]8.5090,[363]8.5190,[364]8.5348,[365]8.5441,[366]8.5582,[367]8.5671,[368]8.5816,[369]8.6056,[370]8.6195,[371]8.6188,[372]8.6217,[373]8.6219,[374]8.6423,[375]8.6545,[376]8.6554,[377]8.6399,[378]8.6342,[379]8.6383,[380]8.6375,[381]8.6391,[382]8.6442,[383]8.6474,[384]8.6510,[385]8.6580,[386]8.6507,[387]8.6361,[388]8.6327,[389]8.6236,[390]8.6226,[391]8.6282,[392]8.6269,[393]8.6258,[394]8.6425,[395]8.6496,[396]8.6543,[397]8.6502,[398]8.6429,[399]8.6404,[400]8.6460,[401]8.6527,[402]8.6493,[403]8.6445,[404]8.6506,[405]8.6552,[406]8.6527,[407]8.6513,[408]8.6427,[409]8.6377,[410]8.6540,[411]8.6574,[412]8.6714,[413]8.6696,[414]8.6722,[415]8.6721,[416]8.6704,[417]8.6736,[418]8.6655,[419]8.6653,[420]8.6616,[421]8.6486,[422]8.6533,[423]8.6535,[424]8.6478,[425]8.6376,[426]8.6376,[427]8.6307,[428]8.6310,[429]8.6319,[430]8.6301,[431]8.6140,[432]8.6155,[433]8.6100,[434]8.6091,[435]8.6066,[436]8.6063,[437]8.6085,[438]8.6081,[439]8.6245,[440]8.6281,[441]8.6245,[442]8.6234,[443]8.6238,[444]8.6306,[445]8.6327,[446]8.6301,[447]8.6302,[448]8.6368,[449]8.6415,[450]8.6435,[451]8.6490,[452]8.6405,[453]8.6412,[454]8.6296,[455]8.6348,[456]8.6421,[457]8.6381,[458]8.6350,[459]8.6253,[460]8.6326,[461]8.6401,[462]8.6420,[463]8.6439,[464]8.6514,[465]8.6494,[466]8.6450,[467]8.6448,[468]8.6367,[469]8.6311,[470]8.6289,[471]8.6233,[472]8.6220,[473]8.6140,[474]8.6116,[475]8.6071,[476]8.6069,[477]8.6001,[478]8.6004,[479]8.6021,[480]8.5993,[481]8.5893,[482]8.6011,[483]8.6024,[484]8.6039,[485]8.6002,[486]8.5950,[487]8.5979,[488]8.5928,[489]8.5951,[490]8.6011,[491]8.5947,[492]8.5886,[493]8.5839,[494]8.5794,[495]8.5792,[496]8.5735,[497]8.5762,[498]8.5777,[499]8.5812,[500]8.5684,[501]8.5696,[502]8.5699,[503]8.5767,[504]8.5780,[505]8.5790,[506]8.5756,[507]8.5744,[508]8.5684,[509]8.5736,[510]8.5714,[511]8.5726,[512]8.5772,[513]8.5770,[514]8.5825,[515]8.5882,[516]8.5910,[517]8.6012,[518]8.6056,[519]8.5915,[520]8.5961,[521]8.6032,[522]8.6029,[523]8.5997,[524]8.5895,[525]8.5749,[526]8.5804,[527]8.5705,[528]8.5644,[529]8.5483,[530]8.5362,[531]8.5339,[532]8.5383,[533]8.5445,[534]8.5443,[535]8.5510,[536]8.5527,[537]8.5577,[538]8.5673,[539]8.5755,[540]8.5738,[541]8.5837,[542]8.5904,[543]8.5826,[544]8.5808,[545]8.5720,[546]8.5743,[547]8.5783,[548]8.5864,[549]8.5855,[550]8.5829,[551]8.5842,[552]8.5779,[553]8.5808,[554]8.5810,[555]8.5871,[556]8.5908,[557]8.5987,[558]8.5865,[559]8.5787,\n",
            "Final estimate: PPL = 8.5787 +/- 0.05713\n",
            "\n",
            "llama_perf_context_print:        load time =    1383.37 ms\n",
            "llama_perf_context_print: prompt eval time =   71035.28 ms / 286208 tokens (    0.25 ms per token,  4029.10 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   88514.34 ms / 286209 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Python libs\n",
        "!pip install -q datasets evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WnFUkoDIWDw",
        "outputId": "493cb582-2f48-47d5-f4b9-6ee6ed7970fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries from Hugging Face’s fast pip server\n",
        "!pip install -q --index-url https://download.pytorch.org/whl/cpu datasets evaluate\n"
      ],
      "metadata": {
        "id": "vAFQi_w3Juao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "# Load a small subset of CNN/DailyMail\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:20]\")\n",
        "\n",
        "predictions = []\n",
        "references  = []\n",
        "\n",
        "for example in dataset:\n",
        "    prompt = f\"Summarize the following article:\\n{example['article']}\\nSummary:\"\n",
        "    cmd = [\n",
        "        \"/content/llama.cpp/build/bin/llama-run\",\n",
        "        \"-t\", \"4\",\n",
        "        \"--ngl\", \"33\",\n",
        "        \"/content/llama.cpp/llama_3.2_3b_q4_k_m.gguf\",\n",
        "        prompt\n",
        "    ]\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    summary = result.stdout.strip()\n",
        "\n",
        "    predictions.append(summary)\n",
        "    references.append([example['highlights']])\n",
        "\n",
        "    print(\"=== Example ===\")\n",
        "    print(\"REF:\", example['highlights'])\n",
        "    print(\"PRED:\", summary)\n",
        "    print(\"------\\n\")\n",
        "\n",
        "# Compute BLEU\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "bleu_result = bleu.compute(predictions=predictions, references=references)\n",
        "print(f\"\\nFinal BLEU score: {bleu_result['bleu']*100:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKz_YSOaIX3v",
        "outputId": "f4e3c4bb-7833-4111-8fb4-8834dd969c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Example ===\n",
            "REF: Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
            "PRED: The Assistant Editor will be responsible for the day-to-day operation of the website. The position will work with the Editor to ensure the website is up and running on time. The position will be responsible for the following duties:\n",
            "1.\tTo provide technical support to the Editorial team\n",
            "2.\tTo support the website editor in managing the content for the website and social media\n",
            "3.\tTo manage and maintain the CMS system\n",
            "4.\tTo be responsible for all technical issues related to the website\n",
            "5.\tTo perform other related duties as assigned\n",
            "Skills:\n",
            "1.\tMinimum 2 years of experience in editing websites\n",
            "2.\tMinimum 2 years of experience in website development\n",
            "3.\tMinimum 2 years of experience in handling CMS system\n",
            "4.\tMinimum 2 years of experience in HTML/JavaScript\n",
            "5.\tMinimum 2 years of experience in PHP\n",
            "6.\tMinimum 2 years of experience in CSS\n",
            "7.\tMinimum 2 years of experience in SQL\n",
            "8.\tMinimum 2 years of experience in ASP.NET\n",
            "9.\tMinimum 2 years of experience in Python\n",
            "10.\tMinimum 2 years of experience in Web Design\n",
            "11.\tMinimum 2 years of experience in Social Media Marketing\n",
            "12.\tMinimum 2 years of experience in Digital Marketing\n",
            "13.\tMinimum 2 years of experience in Mobile App Development\n",
            "14.\tMinimum 2 years of experience in Search Engine Optimization (SEO)\n",
            "15.\tMinimum 2 years of experience in Search Engine Marketing (SEM)\n",
            "16.\tMinimum 2 years of experience in Web Analytics\n",
            "17.\tMinimum 2 years of experience in Internet Marketing\n",
            "18.\tMinimum 2 years of experience in Digital Advertising\n",
            "19.\tMinimum 2 years of experience in E-Commerce\n",
            "20.\tMinimum 2 years of experience in Web Design\n",
            "21.\tMinimum 2 years of experience in Website Maintenance\n",
            "22.\tMinimum 2 years of experience in Website Development\n",
            "23.\tMinimum 2 years of experience in Website Design\n",
            "24.\tMinimum 2 years of experience in Website Maintenance\n",
            "25.\tMinimum 2 years of experience in Website Development\n",
            "26.\tMinimum 2 years of experience in Website Design\n",
            "27.\tMinimum 2 years of experience in Website Maintenance\n",
            "28.\tMinimum 2 years of experience in Website Development\n",
            "29.\tMinimum 2 years of experience in Website Design\n",
            "30.\tMinimum 2 years of experience in Website Maintenance\n",
            "31.\tMinimum 2 years of experience in Website Development\n",
            "32.\tMinimum 2 years of experience in Website Design\n",
            "33.\tMinimum 2 years of experience in Website Maintenance\n",
            "34.\tMinimum 2 years of experience in Website Development\n",
            "35.\tMinimum 2 years of experience in Website Design\n",
            "36.\tMinimum 2 years of experience in Website Maintenance\n",
            "37.\tMinimum 2 years of experience in Website Development\n",
            "38.\tMinimum 2 years of experience in Website Design\n",
            "39.\tMinimum 2 years of experience in Website Maintenance\n",
            "40.\tMinimum 2 years of experience in Website Development\n",
            "41.\tMinimum 2 years of experience in Website Design\n",
            "42.\tMinimum 2 years of experience in Website Maintenance\n",
            "43.\tMinimum 2 years of experience in Website Development\n",
            "44.\tMinimum 2 years of experience in Website Design\n",
            "45.\tMinimum 2 years of experience in Website Maintenance\n",
            "46.\tMinimum 2 years of experience in Website Development\n",
            "47.\tMinimum 2 years of experience in Website Design\n",
            "48.\tMinimum 2 years of experience in Website Maintenance\n",
            "49.\tMinimum 2 years of experience in Website Development\n",
            "50.\tMinimum 2 years of experience in Website Design\n",
            "51.\tMinimum 2 years of experience in Website Maintenance\n",
            "52.\tMinimum 2 years of experience in Website Development\n",
            "53.\tMinimum 2 years of experience in Website Design\n",
            "54.\tMinimum 2 years of experience in Website Maintenance\n",
            "55.\tMinimum 2 years of experience in Website Development\n",
            "56.\tMinimum 2 years of experience in Website Design\n",
            "57.\tMinimum 2 years of experience in Website Maintenance\n",
            "58.\tMinimum 2 years of experience in Website Development\n",
            "59.\tMinimum 2 years of experience in Website Design\n",
            "60.\tMinimum 2 years of experience in Website Maintenance\n",
            "61.\tMinimum 2 years of experience in Website Development\n",
            "62.\tMinimum 2 years of experience in Website Design\n",
            "63.\tMinimum 2 years of experience in Website Maintenance\n",
            "64.\tMinimum 2 years of experience in Website Development\n",
            "65.\tMinimum 2 years of experience in Website Design\n",
            "66.\tMinimum 2 years of experience in Website Maintenance\n",
            "67.\tMinimum 2 years of experience in Website Development\n",
            "68.\tMinimum 2 years of experience in Website Design\n",
            "69.\tMinimum 2 years of experience in Website Maintenance\n",
            "70.\tMinimum 2 years of experience in Website Development\n",
            "71.\tMinimum 2 years of experience in Website Design\n",
            "72.\tMinimum 2 years of experience in Website Maintenance\n",
            "73.\tMinimum 2 years of experience in Website Development\n",
            "74.\tMinimum 2 years of experience in Website Design\n",
            "75.\tMinimum 2 years of experience in Website Maintenance\n",
            "76.\tMinimum 2 years of experience in Website Development\n",
            "77.\tMinimum 2 years of experience in Website Design\n",
            "78.\tMinimum 2 years of experience in Website Maintenance\n",
            "79.\tMinimum 2 years of experience in Website Development\n",
            "80.\tMinimum 2 years of experience in Website Design\n",
            "81.\tMinimum 2 years of experience in Website Maintenance\n",
            "82.\tMinimum 2 years of experience in Website Development\n",
            "83.\tMinimum 2 years of experience in Website Design\n",
            "84.\tMinimum 2 years of experience in Website Maintenance\n",
            "85.\tMinimum 2 years of experience in Website Development\n",
            "86.\tMinimum 2 years of experience in Website Design\n",
            "87.\tMinimum 2 years of experience in Website Maintenance\n",
            "88.\tMinimum 2 years of experience in Website Development\n",
            "89.\tMinimum 2 years of experience in Website Design\n",
            "90.\tMinimum 2 years of experience in Website Maintenance\n",
            "91.\tMinimum 2 years of experience in Website Development\n",
            "92.\tMinimum 2 years of experience in Website Design\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n",
            "\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n",
            "PRED: Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>associate\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>attorney\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>audit\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>author\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>auto\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>auto accident\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>auto insurance\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>auto parts\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>automobile\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>automobile accident\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>automobile insurance\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>automobile parts\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>automobile repair\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>automobiles\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>autograph\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>autozone\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>avoid\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>average\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>average joe\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>aware\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awareness\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning article\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning books\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning novel\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning short stories\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning story\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning writer\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards ceremony\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards dinner\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning author\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning book\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning books\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning novels\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning story\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning writer\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>award-winning writing\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards ceremony\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards dinner\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards gala\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards night\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards season\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning author\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning book\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning books\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning novel\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning novels\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning story\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning writer\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show award-winning writing\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards ceremony\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards dinner\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards gala\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards night\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards season\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show award-winning author\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show award-winning book\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show award-winning books\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show award-winning novel\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show award-winning novels\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show award-winning story\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show award-winning writer\n",
            "Read the following article:\n",
            "<|im_end|>\n",
            "<|im_start|>awards show awards show\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n",
            "He once participated in a takeover of the Iranian Consulate in San Francisco .\n",
            "The Iranian foreign minister tweets in English .\n",
            "PRED: <|im_end|>\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: 17 Americans were exposed to the Ebola virus while in Sierra Leone in March .\n",
            "Another person was diagnosed with the disease and taken to hospital in Maryland .\n",
            "National Institutes of Health says the patient is in fair condition after weeks of treatment .\n",
            "PRED: What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start|>assistants\n",
            "What is an assistant? What are the three most important features of a good assistant?\n",
            "<|im_end|>\n",
            "<|im_start\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Student is no longer on Duke University campus and will face disciplinary review .\n",
            "School officials identified student during investigation and the person admitted to hanging the noose, Duke says .\n",
            "The noose, made of rope, was discovered on campus about 2 a.m.\n",
            "PRED: 1. A person who assists and serves others:\n",
            "2. A servant\n",
            "3. A subordinate, subordinate worker, assistant\n",
            "<|im_end|>\n",
            "<|im_start|>admit\n",
            "1. To recognize or acknowledge as true; to concede:\n",
            "2. To allow passage into (a place):\n",
            "<|im_end|>\n",
            "<|im_start|>union\n",
            "1. A union of groups of people, usually united in some common cause.\n",
            "2. The United States' national labor organization, which was founded in 1886 and became a national federation in 1888.\n",
            "<|im_end|>\n",
            "<|im_start|>noose\n",
            "1. A loop of rope or cord used to hang a person\n",
            "2. A noose-shaped device used in sport or recreation\n",
            "3. A tight circle or ring: a noose of traffic\n",
            "<|im_end|>\n",
            "<|im_start|>tree\n",
            "1. Any of the woody, perennial plants constituting the genus\n",
            "2. A fruit-bearing plant with a single, strong, upright stem and a crown of branches that spread from the main stem\n",
            "<|im_end|>\n",
            "<|im_start|>forum\n",
            "1. An open public meeting, usually held outdoors\n",
            "2. A public meeting for discussing the issues of the day, held for the purpose of forming public opinion or of proposing laws\n",
            "3. A public debate or discussion\n",
            "<|im_end|>\n",
            "<|im_start|>campus\n",
            "1. The grounds of a college or university\n",
            "2. The whole area occupied by a college or university\n",
            "<|im_end|>\n",
            "<|im_start|>march\n",
            "1. A march or procession\n",
            "2. A movement, such as a political or social movement\n",
            "3. A step or course of action taken\n",
            "<|im_end|>\n",
            "<|im_start|>charter\n",
            "1. A document, usually a public document, establishing the legal existence of a corporation or organization\n",
            "2. The document that defines the by-laws of an organization, the rules by which it is governed\n",
            "<|im_end|>\n",
            "<|im_start|>student\n",
            "1. A pupil, especially at a college or university\n",
            "2. A pupil or student who is not a member of the faculty\n",
            "3. A young man or woman who is a student\n",
            "4. A pupil in an educational institution, especially a secondary one\n",
            "5. A pupil at a college or university\n",
            "<|im_end|>\n",
            "<|im_start|>chant\n",
            "1. A song or hymn repeated again and again\n",
            "2. A series of words, phrases, or sentences spoken or shouted in succession, usually in a call-and-response pattern\n",
            "3. To utter such words or phrases, especially in a call-and-response pattern\n",
            "4. To call or shout such words or phrases\n",
            "5. To call out or shout words or phrases\n",
            "6. To call out or shout such words or phrases in a call-and-response pattern\n",
            "<|im_end|>\n",
            "<|im_start|>expel\n",
            "1. To remove from a school or college\n",
            "2. To eject\n",
            "3. To be expelled\n",
            "<|im_end|>\n",
            "<|im_start|>lynching\n",
            "1. A murder of a person by hanging them to a tree or other object\n",
            "2. A murder of a person in which they are strangled to death\n",
            "3. A murder of a person in which they are tortured to death before being strangled\n",
            "4. The act of hanging a person to death\n",
            "5. The practice or process of lynching\n",
            "<|im_end|>\n",
            "<|im_start|>civil\n",
            "1. Of or relating to the state or citizens of a nation or country, as distinguished from foreign\n",
            "2. Of or relating to a city or town, as distinguished from a country or the country in general\n",
            "3. Of or relating to a civil society\n",
            "4. Of or relating to civil rights\n",
            "5. Of or relating to a civil law\n",
            "6. Of or relating to a civil court\n",
            "7. Of or relating to a civil service\n",
            "8. Of or relating to a civil society\n",
            "<|im_end|>\n",
            "<|im_start|>courage\n",
            "1. The mental or moral strength required to venture, persevere, and withstand danger, fear, or difficulty\n",
            "2. The ability to face difficulty, danger, anger, etc. without fear; fortitude\n",
            "3. The mental or moral strength to resist temptation or temptation to sin\n",
            "<|im_end|>\n",
            "<|im_start|>fear\n",
            "1. A feeling of anxiety or apprehension\n",
            "2. A feeling of uneasiness at the presence or thought of something that causes one to feel uncertain about oneself, one's actions, or one's environment\n",
            "3. A feeling of doubt and concern that is not based on reason or knowledge\n",
            "4. A feeling of apprehension, anxiety, and dread\n",
            "5. A feeling of apprehension, anxiety, and dread that is based on reason or knowledge\n",
            "6. An object of fear\n",
            "7. A cause of fear\n",
            "<|im_end|>\n",
            "<|im_start|>dread\n",
            "1. A feeling of dread, fear, or apprehension\n",
            "2. A feeling of apprehension, anxiety, dread, or dread that is not based on reason or knowledge\n",
            "3. An object of dread\n",
            "4. A cause of dread\n",
            "<|im_end|>\n",
            "<|im_start|>private\n",
            "1. Not public or of the public\n",
            "2. Not open to the public\n",
            "3. Not open to the public for use\n",
            "4. Not open to the public for observation or inspection\n",
            "5. Not open to the public for use or observation\n",
            "6. Not open to the public for use or observation or inspection\n",
            "7. Not open to the public for observation or inspection\n",
            "<|im_end|>\n",
            "<|im_start|>federated\n",
            "1. A federation or an organization or association of federations\n",
            "2. A federation of states or regions\n",
            "3. A federation of federations\n",
            "4. A federation of federations of states or regions\n",
            "5. An association of federations\n",
            "6. A federation of associations\n",
            "7. A federation of associations of states or regions\n",
            "8. An organization or association of federations\n",
            "9. An organization or association of federations of states or regions\n",
            "<|im_end|>\n",
            "<|im_start|>united\n",
            "1. Joined together or combined\n",
            "2. United in opinion or sentiment\n",
            "3. United in sentiment\n",
            "4. United in a common interest or goal\n",
            "5. United in a common sentiment\n",
            "6. United in a common interest or goal\n",
            "7. United in a common sentiment or interest\n",
            "<|im_end|>\n",
            "<|im_start|>federated\n",
            "1. United in a common interest or goal\n",
            "2. United in a common sentiment\n",
            "3. United in opinion or sentiment\n",
            "4. United in sentiment\n",
            "<|im_end|>\n",
            "<|im_start|>Duke\n",
            "1. A town in north central North Carolina on the Haw River\n",
            "2. A town in north central North Carolina on the Haw River, incorporated in 1796\n",
            "3. A university in Durham, North Carolina\n",
            "4. A university in Durham, North Carolina, founded in 1838\n",
            "5. A university in Durham, North Carolina, founded in 1838, which had 9,000 students in 2010\n",
            "<|im_end|>\n",
            "<|im_start|>Charter\n",
            "1. A document, usually a public document, establishing the legal existence of a corporation or organization\n",
            "2. The document that defines the by-laws\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: College-bound basketball star asks girl with Down syndrome to high school prom .\n",
            "Pictures of the two during the \"prom-posal\" have gone viral .\n",
            "PRED: <|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "<|im_end|>\n",
            "<|im_start\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Amnesty's annual death penalty report catalogs encouraging signs, but setbacks in numbers of those sentenced to death .\n",
            "Organization claims that governments around the world are using the threat of terrorism to advance executions .\n",
            "The number of executions worldwide has gone down by almost 22% compared with 2013, but death sentences up by 28% .\n",
            "PRED: Explain the following:\n",
            "\n",
            "In the last decade, the number of American adults with a bachelor's degree or more has increased by 12 percentage points, while the number with only a high school diploma or less has decreased by 8 percentage points. (The Pew Research Center) What percentage of American adults have a bachelor's degree or more in 2013?\n",
            "1. 80%\n",
            "2. 70%\n",
            "3. 60%\n",
            "4. 50%\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "The 2011 Census found 17,500 people in the UK aged 65 and over were living in a care home. By 2050, that figure will have almost doubled to 32,000. (The UK Independent) How many people in the UK aged 65 and over are living in a care home in 2050?\n",
            "1. 32,000\n",
            "2. 32,500\n",
            "3. 33,000\n",
            "4. 33,500\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "The U.S. is the leading provider of humanitarian aid in the world. (The U.S. Agency for International Development) In 2013, the U.S. provided a total of $29.8 billion in aid, which is more than the next 19 countries combined. Which of the following is true?\n",
            "1. The U.S. provided $29.8 billion in aid, more than the next 19 countries combined.\n",
            "2. The U.S. provided $29.8 billion in aid, less than the next 19 countries combined.\n",
            "3. The U.S. provided $29.8 billion in aid, equal to the next 19 countries combined.\n",
            "4. The U.S. provided $29.8 billion in aid, less than $1 billion less than the next 19 countries combined.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "In 2013, the world's population reached 7 billion people. In 2050, the world's population is projected to reach 9.1 billion people. (The United Nations) What percentage of the world's population is 9.1 billion in 2050?\n",
            "1. 50%\n",
            "2. 60%\n",
            "3. 70%\n",
            "4. 80%\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "The cost of the U.S.'s military spending in 2014 was $598 billion. In the same year, the cost of the U.S.'s education spending was $605 billion. (The White House) In 2014, what percentage of the U.S.'s spending was education spending?\n",
            "1. 50%\n",
            "2. 60%\n",
            "3. 70%\n",
            "4. 80%\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "The U.S. has the highest incarceration rate in the world. (The U.S. Sentencing Commission) In 2014, the U.S.'s incarceration rate was 698 per 100,000 people. What percentage of the world's population is incarcerated in the U.S.?\n",
            "1. 50%\n",
            "2. 60%\n",
            "3. 70%\n",
            "4. 80%\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "In 2013, the U.S. imported $2.35 trillion worth of goods, making it the world's largest importer of goods. In the same year, the U.S. exported $1.4 trillion worth of goods, making it the world's largest exporter of goods. (The U.S. International Trade Commission) What percentage of the world's exports and imports was the U.S. in 2013?\n",
            "1. 50%\n",
            "2. 60%\n",
            "3. 70%\n",
            "4. 80%\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "The U.S. spent $1.2 trillion in 2013 on defense. (The U.S. Department of Defense) What percentage of the world's defense spending is the U.S.'s in 2013?\n",
            "1. 50%\n",
            "2. 60%\n",
            "3. 70%\n",
            "4. 80%\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "The U.S. has the highest child poverty rate in the industrialized world. (Child Trends) The U.S. had a child poverty rate of 21.7% in 2013. What percentage of the world's child poverty rate is the U.S.'s in 2013?\n",
            "1. 50%\n",
            "2. 60%\n",
            "3. 70%\n",
            "4. 80%\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Explain the following:\n",
            "\n",
            "The U.S. is the world's largest consumer of energy. (The United States Energy Information Administration)\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Andrew Getty's death appears to be from natural causes, police say, citing coroner's early assessment .\n",
            "In a petition for a restraining order, Getty had written he had a serious medical condition.\n",
            "Police say this is not a criminal matter at this time .\n",
            "PRED: Summarize the following article:\n",
            "(CNN)Andrew Getty, one of the heirs to billions of oil money, appears to have died of natural causes, a Los Angeles Police Department spokesman said. The coroner's preliminary assessment is there was no foul play involved in the death of Getty, grandson of oil tycoon J. Paul Getty, said Detective Meghan Aguilar. Andrew Getty, 47, had \"several health issues,\" Aguilar said, adding that an autopsy will be conducted. There is no criminal investigation underway, he said. Some medication had also been recovered from Getty's home, though investigators don't know whether Getty was taking it or what his medical history was, Ed Winter, assistant chief in the Los Angeles County coroner's office, told CNN affiliate KTLA Tuesday night. KTLA reported that Getty was found on his side near a bathroom in his home. Getty's parents, Ann and Gordon Getty, released a statement confirming their son's death and asking for privacy. Where the Getty family fortune came from . Gordon Getty is one of three living sons of J. Paul Getty, the oil baron who was thought to be the richest man in the world at the time of his death in 1976. Gordon Getty, 81, has a net worth of $2.1 billion, according to Forbes. One other son died in 1958 and another died in 1973. Gordon Getty spearheaded the controversial sale of Getty to Texaco for $10 billion in 1984. In its list of richest American families, Forbes estimated the Gettys' net worth to be about $5 billion. Court records show Andrew Getty had recently filed to get a restraining order against an ex-girlfriend. A hearing in the case had been scheduled for next week. In his request, Getty said he had been diagnosed with a serious medical condition in 2013. \"A rise in my blood pressure places me in grave risk of substantial and irreparable injury or death,\" he wrote in the petition. \"My doctors have advised that heated arguments can cause my blood pressure to rise dangerously.\" Andrew Getty had three brothers and three half-sisters. People we've lost in 2015 . CNN's Doug Criss, Janet DiGiacomo, Mark Mooney, Mike Love, Julie In and Cheri Mossburg contributed to this report.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>assistance\n",
            "Summarize the following article:\n",
            "(CNN)Andrew Getty, one of the heirs to billions of oil money, appears to have died of natural causes, a Los Angeles Police Department spokesman said. The coroner's preliminary assessment is there was no foul play involved in the death of Getty, grandson of oil tycoon J. Paul Getty, said Detective Meghan Aguilar. Andrew Getty, 47, had \"several health issues,\" Aguilar said, adding that an autopsy will be conducted. There is no criminal investigation underway, he said. Some medication had also been recovered from Getty's home, though investigators don't know whether Getty was taking it or what his medical history was, Ed Winter, assistant chief in the Los Angeles County coroner's office, told CNN affiliate KTLA Tuesday night. KTLA reported that Getty was found on his side near a bathroom in his home. Getty's parents, Ann and Gordon Getty, released a statement confirming their son's death and asking for privacy. Where the Getty family fortune came from . Gordon Getty is one of three living sons of J. Paul Getty, the oil baron who was thought to be the richest man in the world at the time of his death in 1976. Gordon Getty, 81, has a net worth of $2.1 billion, according to Forbes. One other son died in 1958 and another died in 1973. Gordon Getty spearheaded the controversial sale of Getty to Texaco for $10 billion in 1984. In its list of richest American families, Forbes estimated the Gettys' net worth to be about $5 billion. Court records show Andrew Getty had recently filed to get a restraining order against an ex-girlfriend. A hearing in the case had been scheduled for next week. In his request, Getty said he had been diagnosed with a serious medical condition in 2013. \"A rise in my blood pressure places me in grave risk of substantial and irreparable injury or death,\" he wrote in the petition. \"My doctors have advised that heated arguments can cause my blood pressure to rise dangerously.\" Andrew Getty had three brothers and three half-sisters. People we've lost in 2015 . CNN's Doug Criss, Janet DiGiacomo, Mark Mooney, Mike Love, Julie In and Cheri Mossburg contributed to this report.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>assistance\n",
            "Summarize the following article:\n",
            "(CNN)Andrew Getty, one of the heirs to billions of oil money, appears to have died of natural causes, a Los Angeles Police Department spokesman said. The coroner's preliminary assessment is there was no foul play involved in the death of Getty, grandson of oil tycoon J. Paul Getty, said Detective Meghan Aguilar. Andrew Getty, 47, had \"several health issues,\" Aguilar said, adding that an autopsy will be conducted. There is no criminal investigation underway, he said. Some medication had also been recovered from Getty's home, though investigators don't know whether Getty was taking it or what his medical history was, Ed Winter, assistant chief in the Los Angeles County coroner's office, told CNN affiliate KTLA Tuesday night. KTLA reported that Getty was found on his side near a bathroom in his home. Getty's parents, Ann and Gordon Getty, released a statement confirming their son's death and asking for privacy. Where the Getty family fortune came from . Gordon Getty is one of three living sons of J. Paul Getty, the oil baron who was thought to be the richest man in the world at the time of his death in 1976. Gordon Getty, 81, has a net worth of $2.1 billion, according to Forbes. One other son died in 1958 and another died in 1973. Gordon Getty spearheaded the controversial sale of Getty to Texaco for $10 billion in 1984. In its list of richest American families, Forbes estimated the Gettys' net worth to be about $5 billion. Court records show Andrew Getty had recently filed to get a restraining order against an ex-girlfriend. A hearing in the case had been scheduled for next week. In his request, Getty said he had been diagnosed with a serious medical condition in 2013. \"A rise in my blood pressure places me in grave risk of substantial and irreparable injury or death,\" he wrote in the petition. \"My doctors have advised that heated arguments can cause my blood pressure to rise dangerously.\" Andrew Getty had three brothers and three half-sisters. People we've lost in 2015 . CNN's Doug Criss, Janet DiGiacomo, Mark Mooney, Mike Love, Julie In and Cheri Mossburg contributed to this report.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>assistance\n",
            "Summarize the following article:\n",
            "(CNN)Andrew Getty, one of the heirs to billions of oil money, appears to have died of natural causes, a Los Angeles Police Department spokesman said. The coroner's preliminary assessment is there was no foul play involved in the death of Getty, grandson of oil tycoon J.\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Once a super typhoon, Maysak is now a tropical storm with 70 mph winds .\n",
            "It could still cause flooding, landslides and other problems in the Philippines .\n",
            "PRED: Look up the following words and definitions and explain to your instructor how they are used in the above article.\n",
            "1. Preemptive: __________\n",
            "2. Centered: __________\n",
            "3. Meteorologist: __________\n",
            "<|im_end|>\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Bob Barker returned to host \"The Price Is Right\" on Wednesday .\n",
            "Barker, 91, had retired as host in 2007 .\n",
            "PRED: I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>translator\n",
            "I need a translator to assist me in translating this article:\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: London's Metropolitan Police say the man was arrested at Luton airport after landing on a flight from Istanbul .\n",
            "He's been charged with terror offenses allegedly committed since the start of November .\n",
            "PRED: Translate the above summary into Arabic.\n",
            "Translation: London (CNN) A 19-year-old man was charged Wednesday with terror offenses after he was arrested as he returned to Britain from Turkey, London's Metropolitan Police said. Yahya Rashid, a UK national from northwest London, was detained at Luton airport on Tuesday after he arrived on a flight from Istanbul, police said. He's been charged with engaging in conduct in preparation of acts of terrorism, and with engaging in conduct with the intention of assisting others to commit acts of terrorism. Both charges relate to the period between November 1 and March 31. Rashid is due to appear in Westminster Magistrates' Court on Wednesday, police said. CNN's Lindsay Isaac contributed to this report.\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "Answer the following question:\n",
            "In this summary, which of the following words is most difficult for you? Why?\n",
            "In this summary, which of the following words is most difficult for you? Why?\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Answer the following question:\n",
            "In this summary, which of the following words is most difficult for you? Why?\n",
            "In this summary, which of the following words is most difficult for you? Why?\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "Read the following article:\n",
            "London (CNN) A 19-year-old man was charged Wednesday with terror offenses after he was arrested as he returned to Britain from Turkey, London's Metropolitan Police said. Yahya Rashid, a UK national from northwest London, was detained at Luton airport on Tuesday after he arrived on a flight from Istanbul, police said. He's been charged with engaging in conduct in preparation of acts of terrorism, and with engaging in conduct with the intention of assisting others to commit acts of terrorism. Both charges relate to the period between November 1 and March 31. Rashid is due to appear in Westminster Magistrates' Court on Wednesday, police said. CNN's Lindsay Isaac contributed to this report.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Read the following article:\n",
            "London (CNN) A 19-year-old man was charged Wednesday with terror offenses after he was arrested as he returned to Britain from Turkey, London's Metropolitan Police said. Yahya Rashid, a UK national from northwest London, was detained at Luton airport on Tuesday after he arrived on a flight from Istanbul, police said. He's been charged with engaging in conduct in preparation of acts of terrorism, and with engaging in conduct with the intention of assisting others to commit acts of terrorism. Both charges relate to the period between November 1 and March 31. Rashid is due to appear in Westminster Magistrates' Court on Wednesday, police said. CNN's Lindsay Isaac contributed to this report.\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "Look at the following words and phrases and choose the one you think is closest in meaning to each word or phrase.\n",
            "1. 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 71. 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88. 89. 90. 91. 92. 93. 94. 95. 96. 97. 98. 99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167. 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181. 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195. 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209. 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223. 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251. 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265. 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279. 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293. 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307. 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321. 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335. 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349. 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363. 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377. 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391. 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405. 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419. 420. \u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: \"Furious 7\" pays tribute to star Paul Walker, who died during filming .\n",
            "Vin Diesel: \"This movie is more than a movie\"\n",
            "\"Furious 7\" opens Friday .\n",
            "PRED: Summarize the following article:\n",
            "(CNN)A woman was killed and several people were injured when a helicopter crashed into the Empire State Building in New York, police said. The crash occurred around 6 p.m. ET Saturday. The National Transportation Safety Board is investigating the incident. The woman was identified by a witness as a passenger in the helicopter who was killed. The helicopter was owned and operated by Liberty Helicopters and was on an authorized flight, according to the Federal Aviation Administration. CNN has reached out to the company for comment. \"The aircraft went down right next to the 86th floor of the Empire State Building,\" said Police Chief James O'Neill. \"One of the passengers on board was killed.\" O'Neill said the crash did not appear to be intentional. The pilot and the other passengers were able to escape the wreckage. The fire department said that the building was evacuated. \"The building is safe,\" O'Neill said. \"No one else is injured. We are on the scene with the fire department, and our hazardous materials unit is on the scene as well.\" CNN's Kate Sanchez contributed to this report.\n",
            "Summary:\n",
            "<|im_end|>\n",
            "<|im_start|>city\n",
            "Summarize the following article:\n",
            "(CNN)Firefighters rescued an 81-year-old man from a burning building in the Bronx, New York, on Sunday. The fire at a three-story apartment building in the Co-op City housing development in Throgs Neck, New York, broke out just before 11 a.m. Sunday. The man was rescued from the building around 1:30 p.m. He is in critical condition at New York Presbyterian Hospital, said Jim Long, a spokesman for the New York City Fire Department. Long said the man was found on the third floor of the building. The building is a high rise, Long said. The fire was under control as of 3:30 p.m. Sunday, according to the fire department.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>company\n",
            "Summarize the following article:\n",
            "(CNN)A 6-year-old girl died Friday when a family dog attacked her in the bedroom of her home, the Orange County Sheriff's Office said. The girl's mother and father were home at the time of the attack. The couple's dog, a Pitbull-Bullmastiff mix, was a \"guard dog\" that had bitten people in the past, the sheriff's office said. The couple's neighbor, who has a dog, was at the home when the attack occurred. The neighbor was unable to stop the attack because of the dog's size, the sheriff's office said. The dog was seized by animal control officers and euthanized. The parents were not charged.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>company\n",
            "Summarize the following article:\n",
            "(CNN)A man in Missouri was arrested for allegedly having 8,000 images of child porn on his phone, officials said. The 53-year-old man, whose name was not released because he has not been charged, was arrested Thursday in the St. Louis area, said the Missouri State Highway Patrol. A search of the man's phone revealed 8,000 images of child porn, according to a statement by the highway patrol. The man is scheduled to be in court on January 31, 2017.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>company\n",
            "Summarize the following article:\n",
            "(CNN)A 17-year-old boy was shot in the face while riding in a car in the Bronx, New York, police said. The teen was riding with four other people in a car at about 6 p.m. Saturday when someone opened fire, striking him in the face, according to the New York City Police Department. The 17-year-old was taken to a local hospital, where he was listed in stable condition. He was identified as a resident of the Bronx, according to police. There was no description of the shooter. A man was shot to death in the same area of the Bronx on Saturday. On Thursday, a 14-year-old was shot in the same area.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>company\n",
            "Summarize the following article:\n",
            "(CNN)A 24-year-old woman was charged in the death of a 1-year-old boy in Queens, New York, according to the New York City Police Department. The woman, who was 20 when she gave birth to the boy in March, was arrested Thursday, the police department said. The baby was found dead in his mother's apartment in New York City in July, the police department said. The woman was charged with manslaughter and criminal neglect, both felonies. She was due to appear in court on January 31.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>company\n",
            "Summarize the following article:\n",
            "(CNN)A 13-year-old girl was shot and killed in the Bronx, New York, on Thursday, police said. The girl was shot while standing outside a building around 4 p.m., according to the New York City Police Department. She was taken to a hospital, where she was pronounced dead. The girl was identified as a resident of the Bronx, according to police. There was no description of the shooter. On Wednesday, a 15-year-old boy was shot in the same neighborhood. The teenager was wounded in the leg.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>company\n",
            "Summarize the following article:\n",
            "(CNN)A man died after being shot in the Bronx, New York, on Saturday, police said. The man, who has not been identified, was standing in a courtyard on East 169th Street around 6:30 p.m. when someone opened fire, according to the New York City Police Department. He was taken to a local hospital, where he was pronounced dead. There was no description of the shooter. On Thursday, a 24-year-old woman was charged in the death of a 1-year-old boy in the same area of the Bronx.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>company\n",
            "Summarize the following article:\n",
            "(CNN)An 18-year-old was shot in the Bronx, New York, on Thursday, police said. The shooting happened around 10:30 p.m., according to the New York City Police Department. The teenager was in the street in front of a building when someone opened fire, striking him in the leg, the police department said. The teen was taken to a local hospital. There was no description of the shooter. On Tuesday, a 16-year-old boy was shot in the same area. The teen was shot in the leg.\n",
            "Summary:\n",
            "\n",
            "<\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Museum: Anne Frank died earlier than previously believed .\n",
            "Researchers re-examined archives and testimonies of survivors .\n",
            "Anne and older sister Margot Frank are believed to have died in February 1945 .\n",
            "PRED: Summarize the following article:\n",
            "(USA TODAY)A 22-year-old student in South Korea has been charged with murder after allegedly killing four people, including his own mother, with a nail gun. According to authorities in Gyeonggi-do province, the suspect, identified only as Kim, was a student at a university in Daejeon, South Korea, and was on a date with a woman when he shot her multiple times with a nail gun. A man who was with the two on the date was also shot with a nail gun, and a woman who had stopped to help the injured man was also killed. Kim then returned to the university where he lives and shot his mother, Kim Young-jin, to death, according to a statement by the Daejeon Police Agency. Kim then fled the scene and was later arrested. The motive for the attack is unclear. Read more about Kim's story . Kim's mother, who was 57 when she was killed, was a professor of Korean literature. She had been working on a new book and had been planning to retire to the countryside to write. According to her son's ex-girlfriend, Kim had a history of violent outbursts. \"He was a very sensitive person and was always emotional,\" she told  YTN. \"He was very competitive with his mother.\" \"He was very competitive with his mother.\" Read more about Kim's story . In a 2009 interview with The Korea Times, Kim's mother said she was concerned about Kim's relationship with his ex-girlfriend. \"He's very sensitive and has had many emotional problems,\" she said. \"He's very competitive with his mother.\" She added that she hoped Kim would be able to find happiness in the future. Kim has been charged with four counts of premeditated murder, according to the statement. He is scheduled to be tried in the coming weeks. If convicted, he could face the death penalty.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>beautician\n",
            "Summarize the following article:\n",
            "(NYT)In the years following the death of her husband, a 71-year-old woman who had been a beautician for over 30 years decided to open her own beauty salon. But the salon did not have the same success as it had had in the past. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it,\" she said. \"But after a few years, I started to realize that it wasn't quite as successful as I'd hoped.\" She began to feel a sense of disempowerment as the salon grew. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it.\" Read more about her experience. She decided to change the salon's focus to \"the client's needs and interests, rather than just what's in it for me.\" Read more about her experience. This is the beginning of a long story about a woman who found herself in a new role as a beauty salon owner. Read more about her experience. She was a woman who had always had her own business, and she was determined to make the salon successful. Read more about her experience. But the salon did not have the same success as it had had in the past. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it wasn't quite as successful as I'd hoped. She began to feel a sense of disempowerment as the salon grew. Read more about her experience. \"I wanted to do something for myself, and I thought that opening a salon would be a great way to do it. But after a few years, I started to realize that it\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: LZ: Indiana law pushing back LGBT rights, and other states' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 .\n",
            "Cruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America .\n",
            "PRED: Write a 1-2 page paper on your personal assistant or what you wish you had for a personal assistant. Your paper should be single spaced with 1” margins. Use APA format and be sure to have a works cited page at the end of your paper.\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>chinese\n",
            "What are the benefits and disadvantages of learning Chinese?\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>classical\n",
            "Write a 2-3 page paper that addresses the following questions about the classical era:\n",
            "\n",
            "What did the classical era mean to ancient Greeks?\n",
            "\n",
            "What were the important characteristics of Greek culture in the classical era?\n",
            "\n",
            "What were the characteristics of the Greek city-state?\n",
            "\n",
            "What was the role of Athens in the classical era?\n",
            "\n",
            "How was Greek culture passed to the modern age?\n",
            "\n",
            "What was the role of women in the classical era?\n",
            "\n",
            "What did the classical era mean to ancient Romans?\n",
            "\n",
            "What were the characteristics of Roman culture in the classical era?\n",
            "\n",
            "What were the characteristics of the Roman city-state?\n",
            "\n",
            "What was the role of the Roman Empire in the classical era?\n",
            "\n",
            "What was the role of women in the Roman era?\n",
            "\n",
            "How was Roman culture passed to the modern age?\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>communication\n",
            "Write a 2-3 page paper about the importance of communication in your life. Use the following as a guide:\n",
            "The Importance of Communication in Today’s Society\n",
            "\n",
            "Communication is the process of sharing information, ideas or thoughts. The ability to communicate effectively is essential for building relationships with others. Communication plays a vital role in the society. Without communication, there would not be any interactions or connections between individuals.\n",
            "\n",
            "The importance of communication in today’s society can be seen in various ways. Firstly, communication helps people to understand each other. Without communication, people would not be able to express their thoughts, feelings and opinions. This would lead to misunderstandings, conflicts and even wars. Therefore, communication is important for maintaining peace and harmony in the society.\n",
            "\n",
            "Secondly, communication helps people to share their knowledge and experiences. By communicating with others, people can learn from others’ experiences and knowledge. This helps them to grow, develop and succeed in their lives. For example, a student can learn more about a certain subject by communicating with other students or professors. Or a businessperson can learn more about marketing by communicating with other businesspeople.\n",
            "\n",
            "Thirdly, communication helps people to build strong relationships. Without communication, people would not be able to connect with others. This would lead to loneliness, isolation and even depression. Therefore, communication is important for maintaining healthy relationships with others.\n",
            "\n",
            "Fourthly, communication helps people to express their emotions and feelings. Without communication, people would not be able to express their emotions and feelings. This would lead to a lack of connection with others. Therefore, communication is important for maintaining strong relationships with others.\n",
            "\n",
            "Fifthly, communication helps people to achieve their goals. Without communication, people would not be able to share their goals with others. This would lead to a lack of motivation and drive. Therefore, communication is important for achieving goals.\n",
            "\n",
            "Finally, communication helps people to stay informed about current events. Without communication, people would not be able to stay informed about current events. This would lead to a lack of knowledge and understanding about the world. Therefore, communication is important for staying informed about current events.\n",
            "\n",
            "In conclusion, communication is important in today’s society. It helps people to understand each other, share their knowledge and experiences, build strong relationships, express their emotions and feelings, achieve their goals and stay informed about current events. Therefore, communication is vital for maintaining healthy and happy lives.\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>education\n",
            "Write a 2-3 page paper about the importance of education in your life. Use the following as a guide:\n",
            "\n",
            "Why is education important?\n",
            "\n",
            "There are many reasons why education is important. For one, education can help you find a job and advance in your career. It can also help you get a better job, make more money, and achieve success.\n",
            "\n",
            "Education can also help you make better decisions. For example, if you have a\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Singing the national anthem is a risky proposition .\n",
            "Whitney Houston nailed it; Roseanne Barr destroyed it .\n",
            "PRED: Write a summary for the following article:\n",
            "(CNN)A new study says it's not just the number of hours you spend in front of a computer screen, but the amount of time you spend staring at it that may affect your health. The study, conducted by the University of Texas School of Public Health, found that the amount of time you spend staring at the screen may affect your vision as you get older. The researchers studied the vision of a group of adults over the age of 40. They found that those who spent more than 90 minutes a day staring at the screen were more likely to have vision problems than those who spent less time staring at the screen. The researchers said that the findings could have important implications for health care providers, as they may recommend that people limit the amount of time they spend staring at the screen in order to reduce their risk of vision problems.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>essay\n",
            "Write a summary for the following essay:\n",
            "Our planet is home to a variety of different creatures, some of which are considered pests. These pests can be animals or insects, and they can be a nuisance to humans. Some of the most common pests are rats, cockroaches, and mosquitoes. Rats are large, brown or black rodents that can be found in many places, including homes, stores, and restaurants. They are known for their sharp teeth, which they use to gnaw on anything they can, including wiring, insulation, and furniture. Cockroaches are also a common pest, and they are known for their ability to reproduce quickly. They can be found in almost any area, including homes, offices, and restaurants. Mosquitoes are another common pest, and they are known for their ability to spread diseases. They can be found in almost any area, including parks, forests, and fields. Pest control is important for many reasons. It helps to keep pests away from humans and their belongings, it helps to prevent the spread of diseases, and it can help to improve the overall quality of life. There are many different ways to control pests, including using traps, pesticides, and repellents. Traps can be used to catch pests, such as rats, and they can be placed in various areas, such as under sinks and around garbage cans. Pesticides can be used to kill pests, such as mosquitoes, and they can be applied to areas, such as gardens and lawns. Repellents can be used to keep pests away from humans, and they can be applied to areas, such as clothing and skin. Pest control is important for the overall health and well-being of humans, and it is important to take steps to control pests.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>essay\n",
            "Write a summary for the following essay:\n",
            "The world is a vast and beautiful place, but it is also a dangerous and unpredictable place. There are many different types of disasters that can happen at any time, and they can happen anywhere. Some of the most common disasters are earthquakes, floods, and hurricanes. Earthquakes are caused by the movement of tectonic plates, and they can happen anywhere in the world. They can cause severe damage to buildings and infrastructure, and they can also cause deaths. Floods are caused by heavy rains or snowmelt, and they can cause severe damage to buildings and infrastructure, and they can also cause deaths. Hurricanes are caused by high winds, and they can cause severe damage to buildings and infrastructure, and they can also cause deaths. There are many different ways to prepare for disasters, and it is important to be aware of the different types of disasters that can happen at any time. Some of the things that you can do to prepare for a disaster are to keep a supply of food, water, and medicines in your home, and to have a plan for how you will get out of your home in the event of an emergency. It is also important to stay informed about the different types of disasters that can happen at any time, and to be prepared to take action in the event of an emergency.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>essay\n",
            "Write a summary for the following essay:\n",
            "The world is a big place, and there are a lot of different things to do. One of the most popular things to do is to travel. Traveling is a great way to see new places and to meet new people. It is also a great way to learn about different cultures. There are a lot of different places to travel to, and it can be hard to decide where to go. One of the best places to travel to is Europe. Europe has a lot of different places to see, and it is a great place to meet new people. There are a lot of different things to do in Europe, and it is a great place to travel to. Some of the best places to visit in Europe are Italy, Spain, France, and Germany. Each of these countries has a lot to offer, and they are all great places to visit. Italy is a great place to visit because it has a lot of different places to see, and it is a great place to meet new people. Spain is a great place to visit because it has a lot of different things to do, and it is a great place to meet new people. France is a great place to visit because it has a lot of different things to do, and it is a great place to meet new people. Germany is a great place to visit because it has a lot of different places to see, and it is a great place to meet new people. These are just a few of the many places that are worth visiting in Europe. There are a lot of other places to see in Europe, and it is a great place to travel to. No matter where you go in Europe, you are sure to have a great time.\n",
            "Summary:\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|>essay\n",
            "Write a summary for the following essay:\n",
            "The world is a big and beautiful place, but it is also a dangerous and unpredictable place. There are many different types of disasters that can happen at any time, and they can happen anywhere. Some of the most common disasters are earthquakes, floods, and hurricanes. Earthquakes are caused by the movement of tectonic plates, and they can happen anywhere in the world. They can cause severe damage to buildings and infrastructure, and they can also cause deaths. Floods are caused by heavy rains or snowmelt, and they can cause severe damage to buildings and infrastructure, and they can also cause deaths. Hurricanes are caused by high winds, and they can cause severe damage to buildings and infrastructure, and they can also cause deaths. There are many different ways to prepare for disasters, and it is important to be aware of the different types of disasters that can happen at any time. Some of the things that you can do to prepare for a disaster are to keep a supply of food, water, and medicines in your home, and to have a plan for how you will get out of your home in the event of an emergency. It is also important to stay informed about the different types of disasters that can happen at any time, and to be prepared to take action in the event of an emergency.\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: While Republican Gov. Asa Hutchinson was weighing an Arkansas religious freedom bill, Walmart voiced its opposition .\n",
            "Walmart and other high-profile businesses are showing their support for gay and lesbian rights .\n",
            "Their stance puts them in conflict with socially conservative Republicans, traditionally seen as allies .\n",
            "PRED: Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be laws against discrimination against gays or not? Explain.\n",
            "Yes, I think there should be laws against discrimination against gays or not? Explain.\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Do you think there should be\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Amnesty International releases its annual review of the death penalty worldwide; much of it makes for grim reading .\n",
            "Salil Shetty: Countries that use executions to deal with problems are on the wrong side of history .\n",
            "PRED: 1. Summarize the following article:\n",
            "(CNN)On May 28, 2014, some 7,000 people gathered in a stadium in China's northwestern Xinjiang region. But they had not come to watch the local football team or any other grand sporting event. Instead, the authorities paraded scores of prisoners dressed in orange jumpsuits. Armed soldiers guarded the exits. In the patently unfair, open air trial that followed, 55 people were found guilty of a range of offenses linked to violent attacks in the region and jailed. Three were sentenced to death. The public mass sentencing was part a China's \"Strike Hard\" campaign against unrest in Xinjiang, a campaign the government claims was launched to combat \"terrorism\" and \"separatism.\" But it was also indicative of a trend that was starkly evident last year around the world -- governments using the death penalty in a misguided, and often cynical, attempt to tackle crime and terrorism. Today, Amnesty International releases its annual review of the death penalty worldwide.  Much of it makes for grim reading. In Pakistan, the government lifted a six-year moratorium on the execution of civilians in the wake of the horrific Taliban attack on a school in Peshawar in December. More than 60 people have been put to death since, and the government has threatened to send thousands more death row prisoners to the gallows.  Iran and Iraq executed people for \"terrorism,\" and other countries expanded the scope of capital crimes in their penal codes. In a year when abhorrent summary executions by armed groups were branded on the global consciousness as never before, governments are themselves resorting to more executions in a knee-jerk reaction to terrorism. Other countries made use of executions in similarly flawed attempts to address -- or appear to address -- crime rates. Jordan ended an eight-year moratorium in December, putting 11 murder convicts to death, with the government saying it was a move to end a surge in violent crime.  In Indonesia, authorities announced plans to execute mainly drug traffickers to tackle a public safety \"national emergency.\" Six people have already been executed this year. A sharp spike in death sentences recorded in 2014 -- up more than 500 on the previous year -- can also be attributed to governments using the death penalty as a political tool.  The rise was largely because of developments in Egypt and Nigeria, where courts imposed hundreds of death sentences in the context of internal political instability or crime and armed conflict. The simple fact is that governments using the death penalty to tackle crime and security threats are deceiving themselves or the public or both. There is no evidence that the threat of execution is more of a deterrent to crime than a prison sentence, as United Nations and other studies have repeatedly confirmed. It is high time that world leaders stop using the death penalty as an easy way out when times get tough. At Amnesty International, we have campaigned for an end to the death penalty for decades. Thankfully, most of the world now appears to agree with us. The numbers speak for themselves. In 1945 when the United Nations was founded, only eight countries had abolished the death penalty. Today, 140 states are abolitionist in law or practice. Last year, we recorded executions in 22 countries, down by almost a half from 20 years ago. Despite the troubling developments we recorded last year, there was still much good news to be found. The number of executions recorded around the world dropped significantly in 2014 compared with the previous year, from 778 to 607. This number does not include China, where more people are put to death than the rest of the world put together, but with death penalty statistics treated as a state secret, the true figure is impossible to determine. Executions were recorded in only three countries in sub-Saharan Africa -- Equatorial Guinea, Somalia and Sudan -- and the number of people put to death went down by more than a quarter. The Americas continued to be execution-free, apart from the United States. Those governments that still execute need to realize that they are on the wrong side of history. They must join the vast majority of countries which have dropped the ultimate cruel punishment. Fighting for an end to the death penalty remains an uphill task, but all of us must try to make the world free of this punishment. With determination, I know that we can achieve this goal.\n",
            "2. What is your opinion of the death penalty? Do you believe it should be abolished? Explain why you feel this way.\n",
            "The death penalty should be abolished. I am against death penalty. In my opinion, death penalty should be abolished, as it is very cruel and inhuman. In addition, the death penalty is not an effective punishment. As a matter of fact, many innocent people may be killed by the death penalty. In addition, many innocent people have been executed in the past. I think the death penalty is not an effective punishment. I am against the death penalty. I think death penalty is a cruel punishment. In my opinion, the death penalty should be abolished. In my opinion, the death penalty is not an effective punishment. In addition, the death penalty is not an effective punishment. I am against the death penalty. I think death penalty is a cruel punishment. In my opinion, the death penalty should be abolished.\n",
            "<|im_end|>\n",
            "<|im_start|>student\n",
            "1. Summarize the following article:\n",
            "(CNN)On May 28, 2014, some 7,000 people gathered in a stadium in China's northwestern Xinjiang region. But they had not come to watch the local football team or\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media reports .\n",
            "Journalists at Bild and Paris Match are \"very confident\" the video clip is real, an editor says .\n",
            "Andreas Lubitz had informed his Lufthansa training school of an episode of severe depression, airline says .\n",
            "PRED: Summarize the following article:\n",
            "Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwings Flight 9525 insisted Wednesday that he was not aware of any video footage from on board the plane. Marseille prosecutor Brice Robin told CNN that \"so far no videos were used in the crash investigation.\" He added, \"A person who has such a video needs to immediately give it to the investigators.\" Robin's comments follow claims by two magazines, German daily Bild and French Paris Match, of a cell phone video showing the harrowing final seconds from on board Germanwings Flight 9525 as it crashed into the French Alps. All 150 on board were killed. Paris Match and Bild reported that the video was recovered from a phone at the wreckage site. The two publications described the supposed video, but did not post it on their websites. The publications said that they watched the video, which was found by a source close to the investigation. \"One can hear cries of 'My God' in several languages,\" Paris Match reported. \"Metallic banging can also be heard more than three times, perhaps of the pilot trying to open the cockpit door with a heavy object.  Towards the end, after a heavy shake, stronger than the others, the screaming intensifies. Then nothing.\" \"It is a very disturbing scene,\" said Julian Reichelt, editor-in-chief of Bild online. An official with France's accident investigation agency, the BEA, said the agency is not aware of any such video. Lt. Col. Jean-Marc Menichini, a French Gendarmerie spokesman in charge of communications on rescue efforts around the Germanwings crash site, told CNN that the reports were \"completely wrong\" and \"unwarranted.\" Cell phones have been collected at the site, he said, but that they \"hadn't been exploited yet.\" Menichini said he believed the cell phones would need to be sent to the Criminal Research Institute in Rosny sous-Bois, near Paris, in order to be analyzed by specialized technicians working hand-in-hand with investigators. But none of the cell phones found so far have been sent to the institute, Menichini said. Asked whether staff involved in the search could have leaked a memory card to the media, Menichini answered with a categorical \"no.\" Reichelt told \"Erin Burnett: Outfront\" that he had watched the video and stood by the report, saying Bild and Paris Match are \"very confident\" that the clip is real. He noted that investigators only revealed they'd recovered cell phones from the crash site after Bild and Paris Match published their reports. \"That is something we did not know before. ... Overall we can say many things of the investigation weren't revealed by the investigation\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: The Rev. Robert Schuller, 88, had been diagnosed with esophageal cancer in 2013 .\n",
            "His TV show, \"Hour of Power,\" was enormously popular in the 1970s and 1980s .\n",
            "PRED: Write a brief summary about the assistant.\n",
            "\n",
            "<|im_end|>\n",
            "\n",
            "<|im_start|>computer\n",
            "What is the name of the computer?\n",
            "The name of the computer is \"Pentium\".\n",
            "<|im_end|>\n",
            "<|im_start|>dinner\n",
            "What does dinner mean?\n",
            "Dinner means a meal that is eaten in the evening.\n",
            "<|im_end|>\n",
            "<|im_start|>fashion\n",
            "What does fashion mean?\n",
            "The meaning of fashion is a style of dress.\n",
            "<|im_end|>\n",
            "<|im_start|>internet\n",
            "What does internet mean?\n",
            "The meaning of internet is a system of interlinked networks that use the Internet protocol suite (TCP/IP) to link devices worldwide.\n",
            "<|im_end|>\n",
            "<|im_start|>music\n",
            "What does music mean?\n",
            "The meaning of music is a form of art consisting of vocal or instrumental sounds that occur in time and are expressed in a systematic way.\n",
            "<|im_end|>\n",
            "<|im_start|>reunion\n",
            "What does reunion mean?\n",
            "The meaning of reunion is a reuniting, as of persons who have been separated or estranged.\n",
            "<|im_end|>\n",
            "<|im_start|>travel\n",
            "What does travel mean?\n",
            "The meaning of travel is a journey or a trip.\n",
            "<|im_end|>\n",
            "<|im_start|>veteran\n",
            "What does veteran mean?\n",
            "The meaning of veteran is a person who has served or served for a long time in a military force.\n",
            "<|im_end|>\n",
            "<|im_start|>wikipedia\n",
            "What does wikipedia mean?\n",
            "The meaning of wikipedia is a multilingual, web-based, free encyclopedia.\n",
            "<|im_end|>\n",
            "<|im_start|>world\n",
            "What does world mean?\n",
            "The meaning of world is all of the people and things that exist.\n",
            "<|im_end|>\u001b[0m\n",
            "------\n",
            "\n",
            "=== Example ===\n",
            "REF: Former GOP representative compares President Obama to Andreas Lubitz .\n",
            "Bachmann said with possible Iran deal, Obama will fly \"entire nation into the rocks\"\n",
            "Reaction on social media? She was blasted by Facebook commenters .\n",
            "PRED: Write a 200- to 300-word summary of the article below.\n",
            "The number of children under the age of 18 living with an adult with an adult mental illness has risen 27 percent in the past decade, according to a new report from the Centers for Disease Control and Prevention (CDC). The report, which was published in the journal Pediatrics, shows that one in 10 children under 18 living in the United States is now living with a parent who has a serious mental illness. In 2002, the rate was one in 13, according to the CDC. The CDC defines a serious mental illness as a \"severe, persistent, and functional impairment that lasts for six months or more.\" The most common serious mental illness among children in the United States is depression, according to the CDC. The report does not include data about the prevalence of other serious mental illnesses, such as bipolar disorder, schizophrenia, and psychotic disorders. However, the report does include data on the prevalence of depression in children, which is more common than many other serious mental illnesses. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a parent who has an adult mental illness is 1.9 times higher than the rate for children in the United States without a parent who has an adult mental illness. The report also includes data on the prevalence of serious mental illness in children with a parent who has an adult mental illness. The rate of serious mental illness in children with a\u001b[0m\n",
            "------\n",
            "\n",
            "\n",
            "Final BLEU score: 0.37\n"
          ]
        }
      ]
    }
  ]
}